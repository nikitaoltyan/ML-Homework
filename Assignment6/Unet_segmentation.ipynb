{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Копия блокнота \"image-segmentation-with-unet-pytorch.ipynb\"",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikitaoltyan/ML-Homework/blob/main/Assignment6/Unet_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFcF-cMEFNvC"
      },
      "source": [
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "TyamhUZlFNvD"
      },
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKjhjlXtVT9n"
      },
      "source": [
        "# Run this cell if you are in Colab\n",
        "# Else download data https://drive.google.com/file/d/1AdrduuNb83hvi4cQ-1v-ojhjWL1OUAZr/view?usp=sharing\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "downloaded = drive.CreateFile({'id':\"1AdrduuNb83hvi4cQ-1v-ojhjWL1OUAZr\"})   \n",
        "downloaded.GetContentFile('cityscapes.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czFqu3z6YV8S"
      },
      "source": [
        "! unzip cityscapes.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSPkuxy5FNvE"
      },
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "device = torch.device(device)\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ei-UJGqFNvG"
      },
      "source": [
        "data_dir = \"cityscapes_data\"\n",
        "train_dir = os.path.join(data_dir, \"train\") \n",
        "val_dir = os.path.join(data_dir, \"val\")\n",
        "train_fns = os.listdir(train_dir)\n",
        "val_fns = os.listdir(val_dir)\n",
        "print(len(train_fns), len(val_fns))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHyge3ySFNvG"
      },
      "source": [
        "## 2. Analyze data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjFKPrcmFNvH"
      },
      "source": [
        "sample_image_fp = os.path.join(train_dir, train_fns[0])\n",
        "sample_image = Image.open(sample_image_fp).convert(\"RGB\")\n",
        "plt.imshow(sample_image)\n",
        "print(sample_image_fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isONDiC-FNvI"
      },
      "source": [
        "def split_image(image):\n",
        "    image = np.array(image)\n",
        "    cityscape, label = image[:, :256, :], image[:, 256:, :]\n",
        "    return cityscape, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwaPfwtWFNvI"
      },
      "source": [
        "sample_image = np.array(sample_image)\n",
        "print(sample_image.shape)\n",
        "cityscape, label = split_image(sample_image)\n",
        "print(cityscape.min(), cityscape.max(), label.min(), label.max())\n",
        "cityscape, label = Image.fromarray(cityscape), Image.fromarray(label)\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "axes[0].imshow(cityscape)\n",
        "axes[1].imshow(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYmg2oGXFNvJ"
      },
      "source": [
        "## 3. Define Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfD7w-KEFNvK"
      },
      "source": [
        "\"\"\"\n",
        "color_set = set()\n",
        "for train_fn in tqdm(train_fns[:10]):\n",
        "    train_fp = os.path.join(train_dir, train_fn)\n",
        "    image = np.array(Image.open(train_fp))\n",
        "    cityscape, label = split_image(sample_image)\n",
        "    label = label.reshape(-1, 3)\n",
        "    local_color_set = set([tuple(c) for c in list(label)])\n",
        "    color_set.update(local_color_set)\n",
        "color_array = np.array(list(color_set))\n",
        "\"\"\"\n",
        "\n",
        "num_items = 1000\n",
        "color_array = np.random.choice(range(256), 3*num_items).reshape(-1, 3)\n",
        "print(color_array.shape)\n",
        "print(color_array[:5, :])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ggl-bK9XFNvK"
      },
      "source": [
        "num_classes = 10\n",
        "label_model = KMeans(n_clusters=num_classes)\n",
        "label_model.fit(color_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaOKW7AXFNvL"
      },
      "source": [
        "label_model.predict(color_array[:5, :])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jT3oVN5oFNvL"
      },
      "source": [
        "cityscape, label = split_image(sample_image)\n",
        "label_class = label_model.predict(label.reshape(-1, 3)).reshape(256, 256)\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "axes[0].imshow(cityscape)\n",
        "axes[1].imshow(label)\n",
        "axes[2].imshow(label_class)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wH40AeUHFNvM"
      },
      "source": [
        "label_class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx30smqlemh_"
      },
      "source": [
        "Вопрос: Зачем нужен алгоритм KMeans?  \n",
        "Ответ: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vyCRPYlFNvM"
      },
      "source": [
        "## 4. Define Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SV71LpRlFNvN"
      },
      "source": [
        "class CityscapeDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, image_dir, label_model):\n",
        "        self.image_dir = image_dir\n",
        "        self.image_fns = os.listdir(image_dir)\n",
        "        self.label_model = label_model\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.image_fns)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        image_fn = self.image_fns[index]\n",
        "        image_fp = os.path.join(self.image_dir, image_fn)\n",
        "        image = Image.open(image_fp).convert('RGB')\n",
        "        image = np.array(image)\n",
        "        cityscape, label = self.split_image(image)\n",
        "        label_class = self.label_model.predict(label.reshape(-1, 3)).reshape(256, 256)\n",
        "        cityscape = self.transform(cityscape)\n",
        "        label_class = torch.Tensor(label_class).long()\n",
        "        return cityscape, label_class\n",
        "    \n",
        "    def split_image(self, image):\n",
        "        image = np.array(image)\n",
        "        cityscape, label = image[:, :256, :], image[:, 256:, :]\n",
        "        return cityscape, label\n",
        "    \n",
        "    def transform(self, image):\n",
        "        transform_ops = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
        "        ])\n",
        "        return transform_ops(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHlfFLnlFNvO"
      },
      "source": [
        "dataset = CityscapeDataset(train_dir, label_model)\n",
        "print(len(dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fh2gvnTiFNvO"
      },
      "source": [
        "cityscape, label_class = dataset[0]\n",
        "print(cityscape.shape, label_class.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpQEbt1jFNvP"
      },
      "source": [
        "## 5. Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqabRYHfFNvP"
      },
      "source": [
        "class UNet(nn.Module):\n",
        "    \n",
        "    def __init__(self, num_classes):\n",
        "        super(UNet, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        # TODO: Implement Unet layers\n",
        "        \n",
        "   \n",
        "    def forward(self, X):\n",
        "        # TODO: Implement Unet forward pass\n",
        "        return output_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS0T3DxbFNvU"
      },
      "source": [
        "model = UNet(num_classes=num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bP56VaKwFNvU"
      },
      "source": [
        "data_loader = DataLoader(dataset, batch_size=4)\n",
        "print(len(dataset), len(data_loader))\n",
        "\n",
        "X, Y = iter(data_loader).next()\n",
        "print(X.shape, Y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DzQN10-FNvU"
      },
      "source": [
        "Y_pred = model(X)\n",
        "print(Y_pred.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FOi7QfsFNvV"
      },
      "source": [
        "## 6. Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXBvLUWGFNvV"
      },
      "source": [
        "batch_size = 16\n",
        "\n",
        "epochs = 10\n",
        "lr = 0.01"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmrfb5zHFNvW"
      },
      "source": [
        "dataset = CityscapeDataset(train_dir, label_model)\n",
        "data_loader = DataLoader(dataset, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg2Dab8NFNvW"
      },
      "source": [
        "model = UNet(num_classes=num_classes).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Prks1BX2FNvW"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MACtYYZpFNvX"
      },
      "source": [
        "step_losses = []\n",
        "epoch_losses = []\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    epoch_loss = 0\n",
        "    for X, Y in tqdm(data_loader, total=len(data_loader), leave=False):\n",
        "        X, Y = X.to(device), Y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        Y_pred = model(X)\n",
        "        loss = criterion(Y_pred, Y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        step_losses.append(loss.item())\n",
        "    epoch_losses.append(epoch_loss/len(data_loader))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYyd9KhiFNvX"
      },
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "axes[0].plot(step_losses)\n",
        "axes[1].plot(epoch_losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KODy7ZHgFNvY"
      },
      "source": [
        "model_name = \"U-Net.pth\"\n",
        "torch.save(model.state_dict(), model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyQzUVd7FNvY"
      },
      "source": [
        "## 7. Check model predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQeLAStWFNvZ"
      },
      "source": [
        "model_path = \"U-Net.pth\"\n",
        "model_ = UNet(num_classes=num_classes).to(device)\n",
        "model_.load_state_dict(torch.load(model_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owQQt6moFNvZ"
      },
      "source": [
        "test_batch_size = 8\n",
        "dataset = CityscapeDataset(val_dir, label_model)\n",
        "data_loader = DataLoader(dataset, batch_size=test_batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YlFpLP9FNvZ"
      },
      "source": [
        "X, Y = next(iter(data_loader))\n",
        "X, Y = X.to(device), Y.to(device)\n",
        "Y_pred = model_(X)\n",
        "print(Y_pred.shape)\n",
        "Y_pred = torch.argmax(Y_pred, dim=1)\n",
        "print(Y_pred.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6fSea6AFNva"
      },
      "source": [
        "inverse_transform = transforms.Compose([\n",
        "    transforms.Normalize((-0.485/0.229, -0.456/0.224, -0.406/0.225), (1/0.229, 1/0.224, 1/0.225))\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NffWThT_f4aF"
      },
      "source": [
        "Вопрос: Зачем нужен inverse_transform?  \n",
        "Ответ: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSd1KKeiFNva"
      },
      "source": [
        "fig, axes = plt.subplots(test_batch_size, 3, figsize=(3*5, test_batch_size*5))\n",
        "\n",
        "for i in range(test_batch_size):\n",
        "    \n",
        "    landscape = inverse_transform(X[i]).permute(1, 2, 0).cpu().detach().numpy()\n",
        "    label_class = Y[i].cpu().detach().numpy()\n",
        "    label_class_predicted = Y_pred[i].cpu().detach().numpy()\n",
        "    \n",
        "    axes[i, 0].imshow(landscape)\n",
        "    axes[i, 0].set_title(\"Landscape\")\n",
        "    axes[i, 1].imshow(label_class)\n",
        "    axes[i, 1].set_title(\"Label Class\")\n",
        "    axes[i, 2].imshow(label_class_predicted)\n",
        "    axes[i, 2].set_title(\"Label Class - Predicted\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}